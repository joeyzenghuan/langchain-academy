{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AZURE_OPENAI_ENDPOINT is: https://jz-fdpo-swn.openai.azure.com/\n",
      "正在从本地加载向量存储: C:\\GitRepo\\langchain-academy\\module-4\\agentic-rag\\db\\chroma_db_azure_docs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 指定 .env 文件路径\n",
    "env_path = r'C:\\GitRepo\\langchain-academy\\module-1\\.env'\n",
    "\n",
    "\n",
    "# 加载 .env 文件\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "print(f\"The AZURE_OPENAI_ENDPOINT is: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")\n",
    "\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy-agentic-rag\"\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "azure_openai_llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    ")\n",
    "\n",
    "# embeddings.embed_query(\"Hello, world!\")\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 本地向量存储的路径\n",
    "persist_directory = r\"C:\\GitRepo\\langchain-academy\\module-4\\agentic-rag\\db\\chroma_db_azure_docs\"\n",
    "\n",
    "vectorstore_force_update = False\n",
    "\n",
    "# 检查向量存储是否已存在\n",
    "if os.path.exists(persist_directory) and os.path.isdir(persist_directory) and len(os.listdir(persist_directory)) > 0 and not vectorstore_force_update:\n",
    "    print(f\"正在从本地加载向量存储: {persist_directory}\")\n",
    "    # 直接从本地加载向量存储\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=azure_openai_embeddings,\n",
    "        collection_name=\"rag-chroma-azure-docs-markdown\"\n",
    "    )\n",
    "else:\n",
    "    print(\"本地向量存储不存在，创建新的向量存储...\")\n",
    "    urls = [\n",
    "        # \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "        # \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "        # \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "        \"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\",\n",
    "        \"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\"\n",
    "\n",
    "    ]\n",
    "\n",
    "    docs = [WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000, chunk_overlap=200\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "    # 创建新的向量存储并保存到本地\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_splits,\n",
    "        collection_name=\"rag-chroma\",\n",
    "        persist_directory=persist_directory,\n",
    "        embedding=azure_openai_embeddings,\n",
    "    )\n",
    "    # 保存到本地\n",
    "    # LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
    "    # vectorstore.persist()\n",
    "    print(f\"向量存储已保存到: {persist_directory}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "        \"retrieve_azure_openai_docs\",\n",
    "        \"Search and return information about Azure OpenAI models and content filtering.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\content-filter-original-in-github.md'}, page_content=\"## Best practices\\n\\nAs part of your application design, consider the following best practices to deliver a positive experience with your application while minimizing potential harms:\\n\\n- Decide how you want to handle scenarios where your users send prompts containing content that is classified at a filtered category and severity level or otherwise misuse your application.\\n- Check the `finish_reason` to see if a completion is filtered.\\n- Check that there's no error object in the `content_filter_result` (indicating that content filters didn't run).\\n- If you're using the protected material code model in annotate mode, display the citation URL when you're displaying the code in your application.\\n\\n## Next steps\\n\\n- Learn more about the [underlying models that power Azure OpenAI](../concepts/models.md).\\n- Apply for modified content filters via [this form](https://ncv.microsoft.com/uEfCgnITdR).\\n- Azure OpenAI content filtering is powered by [Azure AI Content Safety](https://azure.microsoft.com/products/cognitive-services/ai-content-safety).\\n- Learn more about understanding and mitigating risks associated with your application: [Overview of Responsible AI practices for Azure OpenAI models](/legal/cognitive-services/openai/overview?context=/azure/ai-services/openai/context/context).\\n- Learn more about how data is processed in connection with content filtering and abuse monitoring: [Data, privacy, and security for Azure OpenAI Service](/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context#preventing-abuse-and-harmful-content-generation).\"),\n",
       " Document(metadata={'source': 'data\\\\content-filter-original-in-github.md'}, page_content=\"---\\ntitle: Azure OpenAI Service content filtering\\ntitleSuffix: Azure OpenAI\\ndescription: Learn about the content filtering capabilities of Azure OpenAI in Azure AI services.\\nauthor: PatrickFarley\\nms.author: pafarley\\nms.service: azure-ai-openai\\nms.topic: conceptual \\nms.date: 03/21/2025\\nms.custom: template-concept, devx-track-python\\nmanager: nitinme\\n---\\n\\n# Content filtering\\n\\n> [!IMPORTANT]\\n> The content filtering system isn't applied to prompts and completions processed by the audio models such as Whisper in Azure OpenAI Service. Learn more about the [Audio models in Azure OpenAI](models.md?tabs=standard-audio#standard-deployment-regional-models-by-endpoint).\\n\\nAzure OpenAI Service includes a content filtering system that works alongside core models, including DALL-E image generation models. This system works by running both the prompt and completion through an ensemble of classification models designed to detect and prevent the output of harmful content. The content filtering system detects and takes action on specific categories of potentially harmful content in both input prompts and output completions. Variations in API configurations and application design might affect completions and thus filtering behavior.\\n\\nThe text content filtering models for the hate, sexual, violence, and self-harm categories have been specifically trained and tested on the following languages: English, German, Japanese, Spanish, French, Italian, Portuguese, and Chinese. However, the service can work in many other languages, but the quality might vary. In all cases, you should do your own testing to ensure that it works for your application.\\n\\nIn addition to the content filtering system, Azure OpenAI Service performs monitoring to detect content and/or behaviors that suggest use of the service in a manner that might violate applicable product terms. For more information about understanding and mitigating risks associated with your application, see the [Transparency Note for Azure OpenAI](/legal/cognitive-services/openai/transparency-note?tabs=text). For more information about how data is processed for content filtering and abuse monitoring, see [Data, privacy, and security for Azure OpenAI Service](/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context#preventing-abuse-and-harmful-content-generation).  \\n\\nThe following sections provide information about the content filtering categories, the filtering severity levels and their configurability, and API scenarios to be considered in application design and implementation. \\n\\n> [!NOTE]\\n> No prompts or completions are stored for the purposes of content filtering. No prompts or completions are used to train, retrain, or improve the content filtering system without your consent. For more information, see [Data, privacy, and security](/legal/cognitive-services/openai/data-privacy?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext&tabs=azure-portal).\\n\\n## Content filter types\\n\\nThe content filtering system integrated in the Azure OpenAI Service contains: \\n* Neural multi-class classification models aimed at detecting and filtering harmful content; the models cover four categories (hate, sexual, violence, and self-harm) across four severity levels (safe, low, medium, and high). Content detected at the 'safe' severity level is labeled in annotations but isn't subject to filtering and isn't configurable.\\n* Other optional classification models aimed at detecting jailbreak risk and known content for text and code; these models are binary classifiers that flag whether user or model behavior qualifies as a jailbreak attack or match to known text or source code. The use of these models is optional, but use of protected material code model may be required for Customer Copyright Commitment coverage.\\n\\n### Risk categories\\n\\n<!--\\nText and image models support Drugs as an additional classification. This category covers advice related to Drugs and depictions of recreational and non-recreational drugs.\\n-->\"),\n",
       " Document(metadata={'source': 'data\\\\content-filter-original-in-github.md'}, page_content='The safety system parses this structured format and applies the following behavior: \\n- On the latest “user” content, the following categories of RAI Risks will be detected: \\n    - Hate \\n    - Sexual \\n    - Violence \\n    - Self-Harm \\n    - Prompt shields (optional) \\n\\nThis is an example message array: \\n\\n```json\\n{\"role\": \"system\", \"content\": \"Provide some context and/or instructions to the model.\"}, \\n{\"role\": \"user\", \"content\": \"Example question goes here.\"}, \\n{\"role\": \"assistant\", \"content\": \"Example answer goes here.\"}, \\n{\"role\": \"user\", \"content\": \"First question/message for the model to actually respond to.\"} \\n```\\n\\n### Embedding documents in your prompt  \\n\\nIn addition to detection on last user content, Azure OpenAI also supports the detection of specific risks inside context documents via Prompt Shields – Indirect Prompt Attack Detection. You should identify parts of the input that are a document (for example, retrieved website, email, etc.) with the following document delimiter.  \\n\\n```\\n\\\\\"\\\\\"\\\\\" <documents> *insert your document content here* </documents> \\\\\"\\\\\"\\\\\" \\n```\\n\\nWhen you do so, the following options are available for detection on tagged documents: \\n- On each tagged “document” content, detect the following categories: \\n    - Indirect attacks (optional) \\n\\nHere\\'s an example chat completion messages array: \\n\\n```json\\n{\"role\": \"system\", \"content\": \"Provide some context and/or instructions to the model.}, \\n\\n{\"role\": \"user\", \"content\": \"First question/message for the model to actually respond to, including document context.  \\\\\"\\\\\"\\\\\" <documents>\\\\n*insert your document content here*\\\\n</documents> \\\\\"\\\\\"\\\\\"\"\"}\\n```\\n\\n#### JSON escaping \\n\\nWhen you tag unvetted documents for detection, the document content should be JSON-escaped to ensure successful parsing by the Azure OpenAI safety system. \\n\\nFor example, see the following email body: \\n\\n```\\nHello Josè, \\n\\nI hope this email finds you well today.\\n```\\n\\nWith JSON escaping, it would read: \\n\\n```\\nHello Jos\\\\u00E9,\\\\nI hope this email finds you well today. \\n```\\n\\nThe escaped text in a chat completion context would read: \\n\\n```json\\n{\"role\": \"system\", \"content\": \"Provide some context and/or instructions to the model, including document context. \\\\\"\\\\\"\\\\\" <documents>\\\\n Hello Jos\\\\\\\\u00E9,\\\\\\\\nI hope this email finds you well today. \\\\n</documents> \\\\\"\\\\\"\\\\\"\"}, \\n\\n{\"role\": \"user\", \"content\": \"First question/message for the model to actually respond to.\"}\\n```\\n\\n## Content streaming\\n\\nThis section describes the Azure OpenAI content streaming experience and options. Customers can receive content from the API as it\\'s generated, instead of waiting for chunks of content that have been verified to pass your content filters.\\n\\n### Default\\n\\nThe content filtering system is integrated and enabled by default for all customers. In the default streaming scenario, completion content is buffered, the content filtering system runs on the buffered content, and – depending on the content filtering configuration – content is either returned to the user if it doesn\\'t violate the content filtering policy (Microsoft\\'s default or a custom user configuration), or it’s immediately blocked and returns a content filtering error, without returning the harmful completion content. This process is repeated until the end of the stream. Content is fully vetted according to the content filtering policy before it\\'s returned to the user. Content isn\\'t returned token-by-token in this case, but in “content chunks” of the respective buffer size.\\n\\n### Asynchronous Filter\\n\\nCustomers can choose the Asynchronous Filter as an extra option, providing a new streaming experience. In this case, content filters are run asynchronously, and completion content is returned immediately with a smooth token-by-token streaming experience. No content is buffered, which allows for a fast streaming experience with zero latency associated with content safety.'),\n",
       " Document(metadata={'source': 'data\\\\content-filter-original-in-github.md'}, page_content='### Asynchronous Filter\\n\\nCustomers can choose the Asynchronous Filter as an extra option, providing a new streaming experience. In this case, content filters are run asynchronously, and completion content is returned immediately with a smooth token-by-token streaming experience. No content is buffered, which allows for a fast streaming experience with zero latency associated with content safety.\\n\\nCustomers must understand that while the feature improves latency, it\\'s a trade-off against the safety and real-time vetting of smaller sections of model output. Because content filters are run asynchronously, content moderation messages and policy violation signals are delayed, which means some sections of harmful content that would otherwise have been filtered immediately could be displayed to the user.\\n \\n**Annotations**: Annotations and content moderation messages are continuously returned during the stream. We strongly recommend you consume annotations in your app and implement other AI content safety mechanisms, such as redacting content or returning other safety information to the user.\\n\\n**Content filtering signal**: The content filtering error signal is delayed. If there is a policy violation, it’s returned as soon as it’s available, and the stream is stopped. The content filtering signal is guaranteed within a ~1,000-character window of the policy-violating content. \\n\\n**Customer Copyright Commitment**: Content that is retroactively flagged as protected material may not be eligible for Customer Copyright Commitment coverage. \\n\\nTo enable Asynchronous Filter in [Azure AI Foundry portal](https://ai.azure.com/), follow the [Content filter how-to guide](/azure/ai-services/openai/how-to/content-filters) to create a new content filtering configuration, and select **Asynchronous Filter** in the Streaming section.\\n\\n### Comparison of content filtering modes\\n\\n| Compare | Streaming - Default | Streaming - Asynchronous Filter |\\n|---|---|---|\\n|Status |GA |Public Preview |\\n| Eligibility |All customers |Customers approved for modified content filtering |\\n| How to enable | Enabled by default, no action needed |Customers approved for modified content filtering can configure it directly in [Azure AI Foundry portal](https://ai.azure.com/) (as part of a content filtering configuration, applied at the deployment level) |\\n|Modality and availability |Text; all GPT models |Text; all GPT models |\\n|Streaming experience |Content is buffered and returned in chunks |Zero latency (no buffering, filters run asynchronously) |\\n|Content filtering signal |Immediate filtering signal |Delayed filtering signal (in up to ~1,000-character increments) |\\n|Content filtering configurations |Supports default and any customer-defined filter setting (including optional models) |Supports default and any customer-defined filter setting (including optional models) |\\n\\n### Annotations and sample responses\\n\\n#### Prompt annotation message\\n\\nThis is the same as default annotations.\\n\\n```json\\ndata: { \\n    \"id\": \"\", \\n    \"object\": \"\", \\n    \"created\": 0, \\n    \"model\": \"\", \\n    \"prompt_filter_results\": [ \\n        { \\n            \"prompt_index\": 0, \\n            \"content_filter_results\": { ... } \\n        } \\n    ], \\n    \"choices\": [], \\n    \"usage\": null \\n} \\n```\\n\\n#### Completion token message\\n\\nCompletion messages are forwarded immediately. No moderation is performed first, and no annotations are provided initially.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is Azure content filtering and how does it work?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-stack-rookie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
