{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e83a41b",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/deployment.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239303-lesson-8-deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20242c4-0010-4065-89f6-0e0b16c7da6e",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "## Review \n",
    "\n",
    "We built up to an agent with memory: \n",
    "\n",
    "* `act` - let the model call specific tools \n",
    "* `observe` - pass the tool output back to the model \n",
    "* `reason` - let the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
    "* `persist state` - use an in memory checkpointer to support long-running conversations with interruptions\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we'll cover how to actually deploy our agent locally to Studio and to `LangGraph Cloud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f348498b-f277-4514-b163-fe5ed9afe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph_sdk langchain_core"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d0f4a7-82ee-4458-bd9a-e246ce2dc4ae",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "There are a few central concepts to understand -\n",
    "\n",
    "`LangGraph` ‚Äî\n",
    "- Python and JavaScript library \n",
    "- Allows creation of agent workflows \n",
    "\n",
    "`LangGraph API` ‚Äî\n",
    "- Bundles the graph code \n",
    "- Provides a task queue for managing asynchronous operations\n",
    "- Offers persistence for maintaining state across interactions\n",
    "\n",
    "`LangGraph Cloud` --\n",
    "- Hosted service for the LangGraph API\n",
    "- Allows deployment of graphs from GitHub repositories\n",
    "- Also provides monitoring and tracing for deployed graphs\n",
    "- Accessible via a unique URL for each deployment\n",
    "\n",
    "`LangGraph Studio` --\n",
    "- Integrated Development Environment (IDE) for LangGraph applications\n",
    "- Uses the API as its back-end, allowing real-time testing and exploration of graphs\n",
    "- Can be run locally or with cloud-deployment\n",
    "\n",
    "`LangGraph SDK` --\n",
    "- Python library for programmatically interacting with LangGraph graphs\n",
    "- Provides a consistent interface for working with graphs, whether served locally or in the cloud\n",
    "- Allows creation of clients, access to assistants, thread management, and execution of runs\n",
    "\n",
    "## Testing Locally\n",
    "\n",
    "**‚ö†Ô∏è DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "Yoo should see the following output:\n",
    "```\n",
    "- üöÄ API: http://127.0.0.1:2024\n",
    "- üé® Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- üìö API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa75ebd4-91fe-42c5-8122-c81e72133477",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b281d8-bd07-4721-922c-347838ceee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c96f353-5dc3-41c8-a3e4-6bf07ca455f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f603e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "URL = \"http://20.40.103.219:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ddf8c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "  'graph_id': 'agentic_rag',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'agentic_rag',\n",
       "  'created_at': '2025-04-26T03:22:58.318487+00:00',\n",
       "  'updated_at': '2025-04-26T03:22:58.318487+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '4fa68834-b850-5590-9ef4-03f78cac5999',\n",
       "  'graph_id': 'research_assistant',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'research_assistant',\n",
       "  'created_at': '2025-04-26T03:22:56.926667+00:00',\n",
       "  'updated_at': '2025-04-26T03:22:56.926667+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '01914b9c-2e77-57a1-bbc3-9f3db62c1c8d',\n",
       "  'graph_id': 'map_reduce',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'map_reduce',\n",
       "  'created_at': '2025-04-26T03:22:56.893669+00:00',\n",
       "  'updated_at': '2025-04-26T03:22:56.893669+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '536dcacf-12a7-5c20-824d-58bc3204bf7a',\n",
       "  'graph_id': 'sub_graphs',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'sub_graphs',\n",
       "  'created_at': '2025-04-26T03:22:56.868923+00:00',\n",
       "  'updated_at': '2025-04-26T03:22:56.868923+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '5ad5db42-a666-551b-b7a7-df27232253be',\n",
       "  'graph_id': 'parallelization',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'parallelization',\n",
       "  'created_at': '2025-04-26T03:22:56.864170+00:00',\n",
       "  'updated_at': '2025-04-26T03:22:56.864170+00:00',\n",
       "  'version': 1,\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1352fa-68ad-4963-890e-c95d93570917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'config': {},\n",
       " 'metadata': {'created_by': 'system'},\n",
       " 'name': 'agent',\n",
       " 'created_at': '2025-04-12T16:17:26.207384+00:00',\n",
       " 'updated_at': '2025-04-12T16:17:26.207384+00:00',\n",
       " 'version': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba9c28a0-d712-496c-b191-7d620589ba33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thread_id': '01b4d75f-8b61-4612-aed2-7a08441aebd6',\n",
       " 'created_at': '2025-04-26T03:28:56.858148+00:00',\n",
       " 'updated_at': '2025-04-26T03:28:56.858154+00:00',\n",
       " 'metadata': {},\n",
       " 'status': 'idle',\n",
       " 'config': {},\n",
       " 'values': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a thread for tracking the state of our run\n",
    "thread = await client.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e4177-3644-43fa-a2f1-08f73292d1a6",
   "metadata": {},
   "source": [
    "Now, we can run our agent [with `client.runs.stream`](https://langchain-ai.github.io/langgraph/concepts/low_level/#stream-and-astream) with:\n",
    "\n",
    "* The `thread_id`\n",
    "* The `graph_id`\n",
    "* The `input` \n",
    "* The `stream_mode`\n",
    "\n",
    "We'll discuss streaming in depth in a future module. \n",
    "\n",
    "For now, just recognize that we are [streaming](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/) the full value of the state after each step of the graph with `stream_mode=\"values\"`.\n",
    " \n",
    "The state is captured in the `chunk.data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65a4480-66b3-48bf-9158-191a7b8c1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'o4-mini 2025-04-16 is supported in which regions?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'ff2c2b62-420b-4b44-aa89-7272ec2f0ba8', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_VB7zDJ4HvavJfAXRcGOwHClp', 'function': {'arguments': '{\"query\":\"o4-mini 2025-04-16 supported regions\"}', 'name': 'retrieve_azure_openai_docs'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0'}, 'type': 'ai', 'name': None, 'id': 'run-ee69a14e-2fe3-42fb-a873-34ede3dd5496-0', 'example': False, 'tool_calls': [{'name': 'retrieve_azure_openai_docs', 'args': {'query': 'o4-mini 2025-04-16 supported regions'}, 'id': 'call_VB7zDJ4HvavJfAXRcGOwHClp', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "{'content': \"| **Region**   |  **gpt-4o**, **2024-05-13**   | **gpt-4o**, **2024-08-06**   | **gpt-4o-mini**, **2024-07-18**   | **gpt-4**, **0613**   | **gpt-4**, **1106-Preview**   | **gpt-4**, **0125-Preview**    | **gpt-4**, **turbo-2024-04-09**   | **gpt-4-32k**, **0613**  | **gpt-35-turbo**, **0613**   | **gpt-35-turbo**, **1106**   | **gpt-35-turbo**, **0125**   | **gpt-35-turbo-16k**, **0613**   |\\n|:-----------------|:--------------------------:|:--------------------------:|:-------------------------------:|:-------------------:|:---------------------------:|:---------------------------:|:-------------------------------:|:-----------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:------------------------------:|\\n| australiaeast    | -                      | -                      | -                           | ‚úÖ                | ‚úÖ                        | -                       | -                           | ‚úÖ                    | ‚úÖ                       | ‚úÖ                       | ‚úÖ                       | ‚úÖ                           |\\n| eastus           | ‚úÖ                       | ‚úÖ                       | ‚úÖ                            | -               | -                       | ‚úÖ                        |  ‚úÖ                            | -                   | ‚úÖ                       | -                      | ‚úÖ                       | ‚úÖ                           |\\n\\n> [!NOTE]\\n> It is expected behavior that the model cannot answer questions about itself. If you want to know when the knowledge cutoff for the model's training data is, or other details about the model you should refer to the model documentation above.\\n\\n## o-series models\\n\\nThe Azure OpenAI o<sup>&#42;</sup> series models are specifically designed to tackle reasoning and problem-solving tasks with increased focus and capability. These models spend more time processing and understanding the user's request, making them exceptionally strong in areas like science, coding, and math compared to previous iterations.\\n\\n|  Model ID  | Description | Max Request (tokens) | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---: |\\n| `o4-mini` (2025-04-16) | - **NEW** reasoning model, offering [enhanced reasoning abilities](../how-to/reasoning.md). <br><br> - Chat Completions API <br> - [Responses API](../how-to/responses.md) <br>- Structured outputs<br> - Text, image processing <br> - Functions/Tools/Parallel tool calling <br> [Full summary of capabilities](../how-to/reasoning.md) | Input: 200,000 <br> Output: 100,000 | May 31, 2024 |   \\n| `o3` (2025-04-16) | - **NEW** reasoning model, offering [enhanced reasoning abilities](../how-to/reasoning.md). <br>  <br> - Chat Completions API <br> - [Responses API](../how-to/responses.md) <br> - Structured outputs<br> - Text, image processing <br> - Functions/Tools/Parallel tool calling <br> [Full summary of capabilities](../how-to/reasoning.md) | Input: 200,000 <br> Output: 100,000 | May 31, 2024 |    \\n| `o3-mini` (2025-01-31) | - [Enhanced reasoning abilities](../how-to/reasoning.md). <br> - Structured outputs<br> - Text-only processing <br> - Functions/Tools | Input: 200,000 <br> Output: 100,000 | Oct 2023 |  \\n| `o1` (2024-12-17) | - [Enhanced reasoning abilities](../how-to/reasoning.md). <br> - Structured outputs<br> - Text, image processing <br> - Functions/Tools | Input: 200,000 <br> Output: 100,000 | Oct 2023 |  \\n|`o1-preview` (2024-09-12) | Older preview version | Input: 128,000  <br> Output: 32,768 | Oct 2023 |\\n| `o1-mini` (2024-09-12) | A faster and more cost-efficient option in the o1 series, ideal for coding tasks requiring speed and lower resource consumption. <br><br> Global standard deployment available by default. <br> <br> Standard (regional) deployments are currently only available for select customers who received access as part of the `o1-preview` limited access release.  | Input: 128,000  <br> Output: 65,536 | Oct 2023 |\\n\\n### Availability\\n\\nTo learn more about the advanced `o-series` models see, [getting started with reasoning models](../how-to/reasoning.md).\\n\\n### Region availability\\n\\n| Model | Region |\\n|---|---|\\n|`o4-mini`|  East US2 (Global Standard) <br> Sweden Central (Global Standard)  |\\n| `o3` |  East US2 (Global Standard) <br> Sweden Central (Global Standard)  |\\n|`o3-mini` | See the [models table](#model-summary-table-and-region-availability). |\\n|`o1` | See the [models table](#model-summary-table-and-region-availability). |\\n| `o1-preview` | See the [models table](#model-summary-table-and-region-availability). This model is only available for customers who were granted access as part of the original limited access |\\n| `o1-mini` | See the [models table](#model-summary-table-and-region-availability). |\\n\\n| uksouth          | -                      | -                      | -                           | -               | ‚úÖ                        | ‚úÖ                        | -                           | -                   | ‚úÖ                       | ‚úÖ                       | ‚úÖ                       | ‚úÖ                           |\\n| westus           | ‚úÖ                       | ‚úÖ                       | ‚úÖ                            | -               | ‚úÖ                        | -                       |‚úÖ                            | -                   | -                      | ‚úÖ                       | ‚úÖ                       | -                          |\\n| westus3          | ‚úÖ                       | ‚úÖ                       | ‚úÖ                            | -               | ‚úÖ                        | -                       | ‚úÖ                            | -                   | -                      | -                      | ‚úÖ                       | -                          |\\n\\n### Capabilities\\n\\n|  Model ID  | Description | Context Window | Max Output Tokens | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---|:---: |\\n| `gpt-4.1` (2025-04-14)   | - Text & image input <br> - Text output <br> - Chat completions API <br>- Responses API <br> - Streaming <br> - Function calling <br> Structured outputs (chat completions)   | 1,047,576 | 32,768 | May 31, 2024 |\\n| `gpt-4.1-nano` (2025-04-14) <br><br> **Fastest 4.1 model** | - Text & image input <br> - Text output <br> - Chat completions API <br>- Responses API <br> - Streaming <br> - Function calling <br> Structured outputs (chat completions)   | 1,047,576  | 32,768 | May 31, 2024 |\\n| `gpt-4.1-mini` (2025-04-14) | - Text & image input <br> - Text output <br> - Chat completions API <br>- Responses API <br> - Streaming <br> - Function calling <br> Structured outputs (chat completions)   | 1,047,576  | 32,768 | May 31, 2024 |\\n\\n\\n## computer-use-preview\\n\\nAn experimental model trained for use with the [Responses API](../how-to/responses.md) computer use tool. It can be used in conjunction with 3rd-party libraries to allow the model to control mouse & keyboard input while getting context from screenshots of the current environment.\\n\\n> [!CAUTION]\\n> We don't recommend using preview models in production. We will upgrade all deployments of preview models to either future preview versions or to the latest stable GA version. Models that are designated preview don't follow the standard Azure OpenAI model lifecycle.\\n\\n### Availability\\n\\n**For access to `computer-use-preview` registration is required, and access will be granted based on Microsoft's eligibility criteria**. Customers who have access to other limited access models will still need to request access for this model.\\n\\nRequest access: [`computer-use-preview` limited access model application](https://aka.ms/oai/cuaaccess)\\n\\nOnce access has been granted, you will need to create a deployment for the model.\\n\\n### Region Availability\\n\\n| Model | Region |\\n|---|---|\\n| `computer-use-preview` | East US 2 (Global Standard) <br> South India (Global Standard) <br> Sweden Central (Global Standard) |\\n\\n### Capabilities\\n\\n|  Model ID  | Description | Context Window | Max Output Tokens | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---|:---: |\\n| `computer-use-preview` (2025-03-11)  | Specialized model for use with the [Responses API](../how-to/responses.md) computer use tool <br> <br>-Tools <br>-Streaming<br>-Text(input/output)<br>- Image(input)   | 8,192 | 1,024 | Oct 2023 |\\n\\n\\n## GPT-4.5 Preview\\n\\n### Region Availability\\n\\n| Model | Region |\\n|---|---|\\n| `gpt-4.5-preview` | East US 2 (Global Standard) <br> Sweden Central (Global Standard) |\\n\\n### Capabilities\\n\\n|  Model ID  | Description | Context Window | Max Output Tokens | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---|:---: |\\n| `gpt-4.5-preview` (2025-02-27) <br> **GPT-4.5 Preview**  | [GPT 4.1](#gpt-41-series) is the recommended replacement for this model. Excels at diverse text and image tasks. <br>-Structured outputs <br>-Prompt caching <br>-Tools <br>-Streaming<br>-Text(input/output)<br>- Image(input)   | 128,000 | 16,384 | Oct 2023 |\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'retrieve_azure_openai_docs', 'id': '0c91778b-bfe6-4181-b7e6-a5ffc4c331c8', 'tool_call_id': 'call_VB7zDJ4HvavJfAXRcGOwHClp', 'artifact': None, 'status': 'success'}\n",
      "{'content': \"| **Region**   |  **gpt-4o**, **2024-05-13**   | **gpt-4o**, **2024-08-06**   | **gpt-4o-mini**, **2024-07-18**   | **gpt-4**, **0613**   | **gpt-4**, **1106-Preview**   | **gpt-4**, **0125-Preview**    | **gpt-4**, **turbo-2024-04-09**   | **gpt-4-32k**, **0613**  | **gpt-35-turbo**, **0613**   | **gpt-35-turbo**, **1106**   | **gpt-35-turbo**, **0125**   | **gpt-35-turbo-16k**, **0613**   |\\n|:-----------------|:--------------------------:|:--------------------------:|:-------------------------------:|:-------------------:|:---------------------------:|:---------------------------:|:-------------------------------:|:-----------------------:|:--------------------------:|:--------------------------:|:--------------------------:|:------------------------------:|\\n| australiaeast    | -                      | -                      | -                           | ‚úÖ                | ‚úÖ                        | -                       | -                           | ‚úÖ                    | ‚úÖ                       | ‚úÖ                       | ‚úÖ                       | ‚úÖ                           |\\n| eastus           | ‚úÖ                       | ‚úÖ                       | ‚úÖ                            | -               | -                       | ‚úÖ                        |  ‚úÖ                            | -                   | ‚úÖ                       | -                      | ‚úÖ                       | ‚úÖ                           |\\n\\n> [!NOTE]\\n> It is expected behavior that the model cannot answer questions about itself. If you want to know when the knowledge cutoff for the model's training data is, or other details about the model you should refer to the model documentation above.\\n\\n## o-series models\\n\\nThe Azure OpenAI o<sup>&#42;</sup> series models are specifically designed to tackle reasoning and problem-solving tasks with increased focus and capability. These models spend more time processing and understanding the user's request, making them exceptionally strong in areas like science, coding, and math compared to previous iterations.\\n\\n|  Model ID  | Description | Max Request (tokens) | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---: |\\n| `o4-mini` (2025-04-16) | - **NEW** reasoning model, offering [enhanced reasoning abilities](../how-to/reasoning.md). <br><br> - Chat Completions API <br> - [Responses API](../how-to/responses.md) <br>- Structured outputs<br> - Text, image processing <br> - Functions/Tools/Parallel tool calling <br> [Full summary of capabilities](../how-to/reasoning.md) | Input: 200,000 <br> Output: 100,000 | May 31, 2024 |   \\n| `o3` (2025-04-16) | - **NEW** reasoning model, offering [enhanced reasoning abilities](../how-to/reasoning.md). <br>  <br> - Chat Completions API <br> - [Responses API](../how-to/responses.md) <br> - Structured outputs<br> - Text, image processing <br> - Functions/Tools/Parallel tool calling <br> [Full summary of capabilities](../how-to/reasoning.md) | Input: 200,000 <br> Output: 100,000 | May 31, 2024 |    \\n| `o3-mini` (2025-01-31) | - [Enhanced reasoning abilities](../how-to/reasoning.md). <br> - Structured outputs<br> - Text-only processing <br> - Functions/Tools | Input: 200,000 <br> Output: 100,000 | Oct 2023 |  \\n| `o1` (2024-12-17) | - [Enhanced reasoning abilities](../how-to/reasoning.md). <br> - Structured outputs<br> - Text, image processing <br> - Functions/Tools | Input: 200,000 <br> Output: 100,000 | Oct 2023 |  \\n|`o1-preview` (2024-09-12) | Older preview version | Input: 128,000  <br> Output: 32,768 | Oct 2023 |\\n| `o1-mini` (2024-09-12) | A faster and more cost-efficient option in the o1 series, ideal for coding tasks requiring speed and lower resource consumption. <br><br> Global standard deployment available by default. <br> <br> Standard (regional) deployments are currently only available for select customers who received access as part of the `o1-preview` limited access release.  | Input: 128,000  <br> Output: 65,536 | Oct 2023 |\\n\\n### Availability\\n\\nTo learn more about the advanced `o-series` models see, [getting started with reasoning models](../how-to/reasoning.md).\\n\\n### Region availability\\n\\n| Model | Region |\\n|---|---|\\n|`o4-mini`|  East US2 (Global Standard) <br> Sweden Central (Global Standard)  |\\n| `o3` |  East US2 (Global Standard) <br> Sweden Central (Global Standard)  |\\n|`o3-mini` | See the [models table](#model-summary-table-and-region-availability). |\\n|`o1` | See the [models table](#model-summary-table-and-region-availability). |\\n| `o1-preview` | See the [models table](#model-summary-table-and-region-availability). This model is only available for customers who were granted access as part of the original limited access |\\n| `o1-mini` | See the [models table](#model-summary-table-and-region-availability). |\\n\\n| uksouth          | -                      | -                      | -                           | -               | ‚úÖ                        | ‚úÖ                        | -                           | -                   | ‚úÖ                       | ‚úÖ                       | ‚úÖ                       | ‚úÖ                           |\\n| westus           | ‚úÖ                       | ‚úÖ                       | ‚úÖ                            | -               | ‚úÖ                        | -                       |‚úÖ                            | -                   | -                      | ‚úÖ                       | ‚úÖ                       | -                          |\\n| westus3          | ‚úÖ                       | ‚úÖ                       | ‚úÖ                            | -               | ‚úÖ                        | -                       | ‚úÖ                            | -                   | -                      | -                      | ‚úÖ                       | -                          |\\n\\n### Capabilities\\n\\n|  Model ID  | Description | Context Window | Max Output Tokens | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---|:---: |\\n| `gpt-4.1` (2025-04-14)   | - Text & image input <br> - Text output <br> - Chat completions API <br>- Responses API <br> - Streaming <br> - Function calling <br> Structured outputs (chat completions)   | 1,047,576 | 32,768 | May 31, 2024 |\\n| `gpt-4.1-nano` (2025-04-14) <br><br> **Fastest 4.1 model** | - Text & image input <br> - Text output <br> - Chat completions API <br>- Responses API <br> - Streaming <br> - Function calling <br> Structured outputs (chat completions)   | 1,047,576  | 32,768 | May 31, 2024 |\\n| `gpt-4.1-mini` (2025-04-14) | - Text & image input <br> - Text output <br> - Chat completions API <br>- Responses API <br> - Streaming <br> - Function calling <br> Structured outputs (chat completions)   | 1,047,576  | 32,768 | May 31, 2024 |\\n\\n\\n## computer-use-preview\\n\\nAn experimental model trained for use with the [Responses API](../how-to/responses.md) computer use tool. It can be used in conjunction with 3rd-party libraries to allow the model to control mouse & keyboard input while getting context from screenshots of the current environment.\\n\\n> [!CAUTION]\\n> We don't recommend using preview models in production. We will upgrade all deployments of preview models to either future preview versions or to the latest stable GA version. Models that are designated preview don't follow the standard Azure OpenAI model lifecycle.\\n\\n### Availability\\n\\n**For access to `computer-use-preview` registration is required, and access will be granted based on Microsoft's eligibility criteria**. Customers who have access to other limited access models will still need to request access for this model.\\n\\nRequest access: [`computer-use-preview` limited access model application](https://aka.ms/oai/cuaaccess)\\n\\nOnce access has been granted, you will need to create a deployment for the model.\\n\\n### Region Availability\\n\\n| Model | Region |\\n|---|---|\\n| `computer-use-preview` | East US 2 (Global Standard) <br> South India (Global Standard) <br> Sweden Central (Global Standard) |\\n\\n### Capabilities\\n\\n|  Model ID  | Description | Context Window | Max Output Tokens | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---|:---: |\\n| `computer-use-preview` (2025-03-11)  | Specialized model for use with the [Responses API](../how-to/responses.md) computer use tool <br> <br>-Tools <br>-Streaming<br>-Text(input/output)<br>- Image(input)   | 8,192 | 1,024 | Oct 2023 |\\n\\n\\n## GPT-4.5 Preview\\n\\n### Region Availability\\n\\n| Model | Region |\\n|---|---|\\n| `gpt-4.5-preview` | East US 2 (Global Standard) <br> Sweden Central (Global Standard) |\\n\\n### Capabilities\\n\\n|  Model ID  | Description | Context Window | Max Output Tokens | Training Data (up to)  |\\n|  --- |  :--- |:--- |:---|:---: |\\n| `gpt-4.5-preview` (2025-02-27) <br> **GPT-4.5 Preview**  | [GPT 4.1](#gpt-41-series) is the recommended replacement for this model. Excels at diverse text and image tasks. <br>-Structured outputs <br>-Prompt caching <br>-Tools <br>-Streaming<br>-Text(input/output)<br>- Image(input)   | 128,000 | 16,384 | Oct 2023 |\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'retrieve_azure_openai_docs', 'id': '0c91778b-bfe6-4181-b7e6-a5ffc4c331c8', 'tool_call_id': 'call_VB7zDJ4HvavJfAXRcGOwHClp', 'artifact': None, 'status': 'success'}\n",
      "{'content': 'The `o4-mini` (2025-04-16) model is supported in the East US2 and Sweden Central regions.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': 'generate', 'id': 'b4f8a42c-6dc6-4c54-9b81-82a4cee0058c', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"o4-mini 2025-04-16 is supported in which regions?\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "        thread['thread_id'],\n",
    "        \"agentic_rag\",\n",
    "        input=input,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbeadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'repeat my last question', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '0e564862-8fcc-46e1-8887-5ee653dd35fa', 'example': False}\n",
      "{'content': '`o4-mini 2025-04-16` is supported in which regions?', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0'}, 'type': 'ai', 'name': None, 'id': 'run-ef6ec145-683b-43e0-90e1-20279672ee1e-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"repeat my last question\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "        thread['thread_id'],\n",
    "        \"agentic_rag\",\n",
    "        input=input,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8708852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'a3802d65-3656-4f2c-a8e7-285962c0508a',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-d79c4646-4334-41a9-8a07-5ec64d268693-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'repeat my last question',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '821ca686-b808-4a8f-b3ab-b520e3f64ac5',\n",
       "     'example': False},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-7ca25b5e-a58c-4077-8d68-8913946a700b-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None}]},\n",
       "  'next': [],\n",
       "  'tasks': [],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a9b-7965-6fd5-ba7d-b115763f4115',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'loop',\n",
       "   'writes': {'agent': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {'finish_reason': 'stop',\n",
       "        'model_name': 'gpt-4o-2024-11-20',\n",
       "        'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "       'type': 'ai',\n",
       "       'name': None,\n",
       "       'id': 'run-7ca25b5e-a58c-4077-8d68-8913946a700b-0',\n",
       "       'example': False,\n",
       "       'tool_calls': [],\n",
       "       'invalid_tool_calls': [],\n",
       "       'usage_metadata': None}]}},\n",
       "   'step': 10,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:48:48.560350+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a9b-9023-60b2-800a-2a9c8cb87323',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a9b-7f47-604b-8009-4d2434e01034',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a9b-9023-60b2-800a-2a9c8cb87323',\n",
       "  'parent_checkpoint_id': '1f021a9b-7f47-604b-8009-4d2434e01034'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'a3802d65-3656-4f2c-a8e7-285962c0508a',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-d79c4646-4334-41a9-8a07-5ec64d268693-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'repeat my last question',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '821ca686-b808-4a8f-b3ab-b520e3f64ac5',\n",
       "     'example': False}]},\n",
       "  'next': ['agent'],\n",
       "  'tasks': [{'id': '498cd082-3e1e-871e-0cf8-5ca999e79be1',\n",
       "    'name': 'agent',\n",
       "    'path': ['__pregel_pull', 'agent'],\n",
       "    'error': None,\n",
       "    'interrupts': [],\n",
       "    'checkpoint': None,\n",
       "    'state': None,\n",
       "    'result': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {'finish_reason': 'stop',\n",
       "        'model_name': 'gpt-4o-2024-11-20',\n",
       "        'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "       'type': 'ai',\n",
       "       'name': None,\n",
       "       'id': 'run-7ca25b5e-a58c-4077-8d68-8913946a700b-0',\n",
       "       'example': False,\n",
       "       'tool_calls': [],\n",
       "       'invalid_tool_calls': [],\n",
       "       'usage_metadata': None}]}}],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a9b-7965-6fd5-ba7d-b115763f4115',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'loop',\n",
       "   'writes': None,\n",
       "   'step': 9,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:48:46.792506+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a9b-7f47-604b-8009-4d2434e01034',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a9b-7f42-6109-8008-ce1ceb043130',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a9b-7f47-604b-8009-4d2434e01034',\n",
       "  'parent_checkpoint_id': '1f021a9b-7f42-6109-8008-ce1ceb043130'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'a3802d65-3656-4f2c-a8e7-285962c0508a',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-d79c4646-4334-41a9-8a07-5ec64d268693-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None}]},\n",
       "  'next': ['__start__'],\n",
       "  'tasks': [{'id': '816eac71-80ee-d2fc-ad3c-4dd267c87b9f',\n",
       "    'name': '__start__',\n",
       "    'path': ['__pregel_pull', '__start__'],\n",
       "    'error': None,\n",
       "    'interrupts': [],\n",
       "    'checkpoint': None,\n",
       "    'state': None,\n",
       "    'result': {'messages': [{'content': 'repeat my last question',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {},\n",
       "       'type': 'human',\n",
       "       'name': None,\n",
       "       'id': None,\n",
       "       'example': False}]}}],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a9b-7965-6fd5-ba7d-b115763f4115',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'input',\n",
       "   'writes': {'__start__': {'messages': [{'content': 'repeat my last question',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {},\n",
       "       'type': 'human',\n",
       "       'name': None,\n",
       "       'id': None,\n",
       "       'example': False}]}},\n",
       "   'step': 8,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:48:46.790477+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a9b-7f42-6109-8008-ce1ceb043130',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a99-d5e4-6d34-8007-3c281b986d48',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a9b-7f42-6109-8008-ce1ceb043130',\n",
       "  'parent_checkpoint_id': '1f021a99-d5e4-6d34-8007-3c281b986d48'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'a3802d65-3656-4f2c-a8e7-285962c0508a',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-d79c4646-4334-41a9-8a07-5ec64d268693-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None}]},\n",
       "  'next': [],\n",
       "  'tasks': [],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a99-bf8e-6ed9-ba86-313d29ccadf7',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'loop',\n",
       "   'writes': {'agent': {'messages': [{'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {'finish_reason': 'stop',\n",
       "        'model_name': 'gpt-4o-2024-11-20',\n",
       "        'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "       'type': 'ai',\n",
       "       'name': None,\n",
       "       'id': 'run-d79c4646-4334-41a9-8a07-5ec64d268693-0',\n",
       "       'example': False,\n",
       "       'tool_calls': [],\n",
       "       'invalid_tool_calls': [],\n",
       "       'usage_metadata': None}]}},\n",
       "   'step': 7,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:48:02.187806+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a99-d5e4-6d34-8007-3c281b986d48',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a99-c553-65c2-8006-6597d972556a',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a99-d5e4-6d34-8007-3c281b986d48',\n",
       "  'parent_checkpoint_id': '1f021a99-c553-65c2-8006-6597d972556a'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'a3802d65-3656-4f2c-a8e7-285962c0508a',\n",
       "     'example': False}]},\n",
       "  'next': ['agent'],\n",
       "  'tasks': [{'id': '7e5c324f-9a63-eefb-28e2-9069d711c88f',\n",
       "    'name': 'agent',\n",
       "    'path': ['__pregel_pull', 'agent'],\n",
       "    'error': None,\n",
       "    'interrupts': [],\n",
       "    'checkpoint': None,\n",
       "    'state': None,\n",
       "    'result': {'messages': [{'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {'finish_reason': 'stop',\n",
       "        'model_name': 'gpt-4o-2024-11-20',\n",
       "        'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "       'type': 'ai',\n",
       "       'name': None,\n",
       "       'id': 'run-d79c4646-4334-41a9-8a07-5ec64d268693-0',\n",
       "       'example': False,\n",
       "       'tool_calls': [],\n",
       "       'invalid_tool_calls': [],\n",
       "       'usage_metadata': None}]}}],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a99-bf8e-6ed9-ba86-313d29ccadf7',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'loop',\n",
       "   'writes': None,\n",
       "   'step': 6,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:48:00.450502+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a99-c553-65c2-8006-6597d972556a',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a99-c548-64ba-8005-085b15d334b9',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a99-c553-65c2-8006-6597d972556a',\n",
       "  'parent_checkpoint_id': '1f021a99-c548-64ba-8005-085b15d334b9'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None}]},\n",
       "  'next': ['__start__'],\n",
       "  'tasks': [{'id': '0fb4b562-1901-6df9-3b5f-8219c5a3ffcc',\n",
       "    'name': '__start__',\n",
       "    'path': ['__pregel_pull', '__start__'],\n",
       "    'error': None,\n",
       "    'interrupts': [],\n",
       "    'checkpoint': None,\n",
       "    'state': None,\n",
       "    'result': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {},\n",
       "       'type': 'human',\n",
       "       'name': None,\n",
       "       'id': None,\n",
       "       'example': False}]}}],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a99-bf8e-6ed9-ba86-313d29ccadf7',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'input',\n",
       "   'writes': {'__start__': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {},\n",
       "       'type': 'human',\n",
       "       'name': None,\n",
       "       'id': None,\n",
       "       'example': False}]}},\n",
       "   'step': 5,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:48:00.445970+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a99-c548-64ba-8005-085b15d334b9',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a99-5ae7-6f73-8004-e9332141bc5e',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a99-c548-64ba-8005-085b15d334b9',\n",
       "  'parent_checkpoint_id': '1f021a99-5ae7-6f73-8004-e9332141bc5e'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None}]},\n",
       "  'next': [],\n",
       "  'tasks': [],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a99-4294-6f94-8af3-893eff414499',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'loop',\n",
       "   'writes': {'agent': {'messages': [{'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {'finish_reason': 'stop',\n",
       "        'model_name': 'gpt-4o-2024-11-20',\n",
       "        'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "       'type': 'ai',\n",
       "       'name': None,\n",
       "       'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "       'example': False,\n",
       "       'tool_calls': [],\n",
       "       'invalid_tool_calls': [],\n",
       "       'usage_metadata': None}]}},\n",
       "   'step': 4,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:47:49.291608+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a99-5ae7-6f73-8004-e9332141bc5e',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a99-47c3-651d-8003-b63e7ed13a3e',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a99-5ae7-6f73-8004-e9332141bc5e',\n",
       "  'parent_checkpoint_id': '1f021a99-47c3-651d-8003-b63e7ed13a3e'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None},\n",
       "    {'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': '60921c61-21be-4cb0-ade6-bbeaffde10b9',\n",
       "     'example': False}]},\n",
       "  'next': ['agent'],\n",
       "  'tasks': [{'id': '386c2247-09b4-3f58-a590-a725ae70407c',\n",
       "    'name': 'agent',\n",
       "    'path': ['__pregel_pull', 'agent'],\n",
       "    'error': None,\n",
       "    'interrupts': [],\n",
       "    'checkpoint': None,\n",
       "    'state': None,\n",
       "    'result': {'messages': [{'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {'finish_reason': 'stop',\n",
       "        'model_name': 'gpt-4o-2024-11-20',\n",
       "        'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "       'type': 'ai',\n",
       "       'name': None,\n",
       "       'id': 'run-889871ae-33d3-4b01-ba51-ff60e06eda59-0',\n",
       "       'example': False,\n",
       "       'tool_calls': [],\n",
       "       'invalid_tool_calls': [],\n",
       "       'usage_metadata': None}]}}],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a99-4294-6f94-8af3-893eff414499',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'loop',\n",
       "   'writes': None,\n",
       "   'step': 3,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:47:47.284303+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a99-47c3-651d-8003-b63e7ed13a3e',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a99-47bb-6f54-8002-1f2d7e87cf11',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a99-47c3-651d-8003-b63e7ed13a3e',\n",
       "  'parent_checkpoint_id': '1f021a99-47bb-6f54-8002-1f2d7e87cf11'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None}]},\n",
       "  'next': ['__start__'],\n",
       "  'tasks': [{'id': '54bee06f-253c-71a9-70e9-ada9be6f5c83',\n",
       "    'name': '__start__',\n",
       "    'path': ['__pregel_pull', '__start__'],\n",
       "    'error': None,\n",
       "    'interrupts': [],\n",
       "    'checkpoint': None,\n",
       "    'state': None,\n",
       "    'result': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {},\n",
       "       'type': 'human',\n",
       "       'name': None,\n",
       "       'id': None,\n",
       "       'example': False}]}}],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a99-4294-6f94-8af3-893eff414499',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'input',\n",
       "   'writes': {'__start__': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {},\n",
       "       'type': 'human',\n",
       "       'name': None,\n",
       "       'id': None,\n",
       "       'example': False}]}},\n",
       "   'step': 2,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:47:47.281288+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a99-47bb-6f54-8002-1f2d7e87cf11',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a98-89c4-60a1-8001-fb84cb9500ba',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a99-47bb-6f54-8002-1f2d7e87cf11',\n",
       "  'parent_checkpoint_id': '1f021a98-89c4-60a1-8001-fb84cb9500ba'},\n",
       " {'values': {'messages': [{'content': 'Multiply 3 by 2.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'cd48fc40-8eea-41bb-864e-1432f951b5ca',\n",
       "     'example': False},\n",
       "    {'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {'finish_reason': 'stop',\n",
       "      'model_name': 'gpt-4o-2024-11-20',\n",
       "      'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "     'type': 'ai',\n",
       "     'name': None,\n",
       "     'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "     'example': False,\n",
       "     'tool_calls': [],\n",
       "     'invalid_tool_calls': [],\n",
       "     'usage_metadata': None}]},\n",
       "  'next': [],\n",
       "  'tasks': [],\n",
       "  'metadata': {'langgraph_auth_user': None,\n",
       "   'langgraph_auth_user_id': '',\n",
       "   'langgraph_auth_permissions': [],\n",
       "   'graph_id': 'agentic_rag',\n",
       "   'assistant_id': '3af879da-c2f1-5ca9-8f31-504657f2c8df',\n",
       "   'user_id': '',\n",
       "   'created_by': 'system',\n",
       "   'run_attempt': 1,\n",
       "   'langgraph_version': '0.3.31',\n",
       "   'langgraph_plan': 'developer',\n",
       "   'langgraph_host': 'self-hosted',\n",
       "   'run_id': '1f021a98-7103-6d1e-8eb5-83cecf3c1f86',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'source': 'loop',\n",
       "   'writes': {'agent': {'messages': [{'content': 'The result of multiplying 3 by 2 is **6**.',\n",
       "       'additional_kwargs': {},\n",
       "       'response_metadata': {'finish_reason': 'stop',\n",
       "        'model_name': 'gpt-4o-2024-11-20',\n",
       "        'system_fingerprint': 'fp_ee1d74bde0'},\n",
       "       'type': 'ai',\n",
       "       'name': None,\n",
       "       'id': 'run-bd7808d3-45ed-414c-b16b-8100237b7e30-0',\n",
       "       'example': False,\n",
       "       'tool_calls': [],\n",
       "       'invalid_tool_calls': [],\n",
       "       'usage_metadata': None}]}},\n",
       "   'step': 1,\n",
       "   'parents': {}},\n",
       "  'created_at': '2025-04-25T07:47:27.361654+00:00',\n",
       "  'checkpoint': {'checkpoint_id': '1f021a98-89c4-60a1-8001-fb84cb9500ba',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'parent_checkpoint': {'checkpoint_id': '1f021a98-782e-6921-8000-6d60cec19ebd',\n",
       "   'thread_id': '101b525d-0ad2-465f-b5f5-f56e2abd477c',\n",
       "   'checkpoint_ns': ''},\n",
       "  'checkpoint_id': '1f021a98-89c4-60a1-8001-fb84cb9500ba',\n",
       "  'parent_checkpoint_id': '1f021a98-782e-6921-8000-6d60cec19ebd'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_state = await client.threads.get_history(\n",
    "        thread_id=thread['thread_id'],\n",
    "        #   limit=5,\n",
    "    )\n",
    "thread_state."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa8b850-750c-4054-95e4-1c457a12ec8a",
   "metadata": {},
   "source": [
    "## Testing with Cloud\n",
    "\n",
    "We can deploy to Cloud via LangSmith, as outlined [here](https://langchain-ai.github.io/langgraph/cloud/quick_start/#deploy-from-github-with-langgraph-cloud). \n",
    "\n",
    "### Create a New Repository on GitHub\n",
    "\n",
    "* Go to your GitHub account\n",
    "* Click on the \"+\" icon in the upper-right corner and select `\"New repository\"`\n",
    "* Name your repository (e.g., `langchain-academy`)\n",
    "\n",
    "### Add Your GitHub Repository as a Remote\n",
    "\n",
    "* Go back to your terminal where you cloned `langchain-academy` at the start of this course\n",
    "* Add your newly created GitHub repository as a remote\n",
    "\n",
    "```\n",
    "git remote add origin https://github.com/your-username/your-repo-name.git\n",
    "```\n",
    "* Push to it\n",
    "```\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "### Connect LangSmith to your GitHub Repository\n",
    "\n",
    "* Go to [LangSmith](hhttps://smith.langchain.com/)\n",
    "* Click on `deployments` tab on the left LangSmith panel\n",
    "* Add `+ New Deployment`\n",
    "* Then, select the Github repository (e.g., `langchain-academy`) that you just created for the course\n",
    "* Point the `LangGraph API config file` at one of the `studio` directories\n",
    "* For example, for module-1 use: `module-1/studio/langgraph.json`\n",
    "* Set your API keys (e.g., you can just copy from your `module-1/studio/.env` file)\n",
    "\n",
    "![Screenshot 2024-09-03 at 11.35.12 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fd61c93d48e5d0f47_deployment2.png)\n",
    "\n",
    "### Work with your deployment\n",
    "\n",
    "We can then interact with our deployment a few different ways:\n",
    "\n",
    "* With the [SDK](https://langchain-ai.github.io/langgraph/cloud/quick_start/#use-with-the-sdk), as before.\n",
    "* With [LangGraph Studio](https://langchain-ai.github.io/langgraph/cloud/quick_start/#interact-with-your-deployment-via-langgraph-studio).\n",
    "\n",
    "![Screenshot 2024-08-23 at 10.59.36 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fa159a09a51d601de_deployment3.png)\n",
    "\n",
    "To use the SDK here in the notebook, simply ensure that `LANGSMITH_API_KEY` is set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646ed351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda16c-c87f-4c03-b910-d647e83400b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the URL of your deployed graph\n",
    "URL = \"https://langchain-academy-8011c561878d50b1883f7ed11b32d720.default.us.langgraph.app\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefa37c0-92fe-4e80-9d5a-80a77b1e3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the agent\n",
    "agent = assistants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b810376e-f20f-443a-b1ca-d6793f358f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'created_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'updated_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'config': {},\n",
       " 'metadata': {'created_by': 'system'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32d65d84-1bcf-4af4-a7c9-55e73d6c1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Multiply 3 by 2.', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '8ea04559-f7d4-4c82-89d9-c60fb0502f21', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-b0ea5ddd-e9ba-4242-bb8c-80eb52466c76', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '1bf558e7-79ef-4f21-bb66-acafbd04677a', 'tool_call_id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'artifact': None, 'status': 'success'}\n",
      "{'content': '3 multiplied by 2 equals 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-ecc4b6ad-af15-4a85-a76c-de2ed0ed8ed9', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# We create a thread for tracking the state of our run\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"Multiply 3 by 2.\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "        thread['thread_id'],\n",
    "        \"agent\",\n",
    "        input=input,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cb34d-c3b8-4446-a7e3-5fe938abf99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-stack-rookie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
